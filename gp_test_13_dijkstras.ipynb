{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from argparse import Namespace\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bax.models.simple_gp import SimpleGp\n",
    "from bax.alg.algorithms import Dijkstras\n",
    "from bax.acq.acqoptimize import AcqOptimizer\n",
    "\n",
    "from bax.util.graph import Vertex, make_vertices, make_edges, farthest_pair\n",
    "\n",
    "import neatplot\n",
    "neatplot.set_style('fonts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a grid\n",
    "\n",
    "g = 10\n",
    "x1, x2 = np.meshgrid(np.linspace(-1, 1, g), np.linspace(-1, 1, g))\n",
    "positions = np.stack([x1.flatten(), x2.flatten()], axis=-1)\n",
    "n = len(positions)\n",
    "\n",
    "has_edge = [[False for _ in range(n)] for _ in range(n)]\n",
    "for i in range(n):\n",
    "    for j in range(i + 1, n):\n",
    "        if ((abs(i - j) == 1) and (j % g != 0)):\n",
    "            has_edge[i][j] = True\n",
    "        elif (abs(i - j) == g):\n",
    "            has_edge[i][j] = True\n",
    "        else:\n",
    "            has_edge[i][j] = False\n",
    "has_edge = np.array(has_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True, False, ..., False, False, False],\n",
       "       [False, False,  True, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False,  True, False],\n",
       "       [False, False, False, ..., False, False,  True],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = make_vertices(positions, has_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [1, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = make_edges(vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a graph\n",
    "def l2_dist(u: Vertex, v: Vertex):\n",
    "    return np.sqrt(np.sum((u.position - v.position)**2))\n",
    "\n",
    "start, goal = farthest_pair(vertices, distance_func=l2_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*[INFO] SimpleGp with params=Namespace(alpha=1.0, kernel=<function kern_exp_quad at 0x7f7a89e9d430>, ls=1.0, name='SimpleGp', sigma=0.01)\n",
      "*[INFO] Dijkstras with params=Namespace(goal=(99, [89, 98]), name='Dijkstras', start=(0, [1, 10]), vertices=[(0, [1, 10]), (1, [0, 2, 11]), (2, [1, 3, 12]), (3, [2, 4, 13]), (4, [3, 5, 14]), (5, [4, 6, 15]), (6, [5, 7, 16]), (7, [6, 8, 17]), (8, [7, 9, 18]), (9, [8, 19]), (10, [0, 11, 20]), (11, [1, 10, 12, 21]), (12, [2, 11, 13, 22]), (13, [3, 12, 14, 23]), (14, [4, 13, 15, 24]), (15, [5, 14, 16, 25]), (16, [6, 15, 17, 26]), (17, [7, 16, 18, 27]), (18, [8, 17, 19, 28]), (19, [9, 18, 29]), (20, [10, 21, 30]), (21, [11, 20, 22, 31]), (22, [12, 21, 23, 32]), (23, [13, 22, 24, 33]), (24, [14, 23, 25, 34]), (25, [15, 24, 26, 35]), (26, [16, 25, 27, 36]), (27, [17, 26, 28, 37]), (28, [18, 27, 29, 38]), (29, [19, 28, 39]), (30, [20, 31, 40]), (31, [21, 30, 32, 41]), (32, [22, 31, 33, 42]), (33, [23, 32, 34, 43]), (34, [24, 33, 35, 44]), (35, [25, 34, 36, 45]), (36, [26, 35, 37, 46]), (37, [27, 36, 38, 47]), (38, [28, 37, 39, 48]), (39, [29, 38, 49]), (40, [30, 41, 50]), (41, [31, 40, 42, 51]), (42, [32, 41, 43, 52]), (43, [33, 42, 44, 53]), (44, [34, 43, 45, 54]), (45, [35, 44, 46, 55]), (46, [36, 45, 47, 56]), (47, [37, 46, 48, 57]), (48, [38, 47, 49, 58]), (49, [39, 48, 59]), (50, [40, 51, 60]), (51, [41, 50, 52, 61]), (52, [42, 51, 53, 62]), (53, [43, 52, 54, 63]), (54, [44, 53, 55, 64]), (55, [45, 54, 56, 65]), (56, [46, 55, 57, 66]), (57, [47, 56, 58, 67]), (58, [48, 57, 59, 68]), (59, [49, 58, 69]), (60, [50, 61, 70]), (61, [51, 60, 62, 71]), (62, [52, 61, 63, 72]), (63, [53, 62, 64, 73]), (64, [54, 63, 65, 74]), (65, [55, 64, 66, 75]), (66, [56, 65, 67, 76]), (67, [57, 66, 68, 77]), (68, [58, 67, 69, 78]), (69, [59, 68, 79]), (70, [60, 71, 80]), (71, [61, 70, 72, 81]), (72, [62, 71, 73, 82]), (73, [63, 72, 74, 83]), (74, [64, 73, 75, 84]), (75, [65, 74, 76, 85]), (76, [66, 75, 77, 86]), (77, [67, 76, 78, 87]), (78, [68, 77, 79, 88]), (79, [69, 78, 89]), (80, [70, 81, 90]), (81, [71, 80, 82, 91]), (82, [72, 81, 83, 92]), (83, [73, 82, 84, 93]), (84, [74, 83, 85, 94]), (85, [75, 84, 86, 95]), (86, [76, 85, 87, 96]), (87, [77, 86, 88, 97]), (88, [78, 87, 89, 98]), (89, [79, 88, 99]), (90, [80, 91]), (91, [81, 90, 92]), (92, [82, 91, 93]), (93, [83, 92, 94]), (94, [84, 93, 95]), (95, [85, 94, 96]), (96, [86, 95, 97]), (97, [87, 96, 98]), (98, [88, 97, 99]), (99, [89, 98])])\n"
     ]
    }
   ],
   "source": [
    "# Set function\n",
    "f = lambda x: x[0]**2 + x[1]**2\n",
    "\n",
    "# Set data for model\n",
    "data = Namespace()\n",
    "data.x = []\n",
    "data.y = [f(x) for x in data.x]\n",
    "\n",
    "# Set model as a GP\n",
    "gp_params = {'ls': 1.0, 'alpha': 1.0, 'sigma': 1e-2}\n",
    "model = SimpleGp(gp_params)\n",
    "model.set_data(data)\n",
    "\n",
    "# Set algorithm\n",
    "algo = Dijkstras({\n",
    "    'start': start,\n",
    "    'goal': goal,\n",
    "    'vertices': vertices})\n",
    "\n",
    "x_test = [positions] # input points to maximize acquisition function over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*[INFO] AcqOptimizer with params=Namespace(acq_str='exe', n_path=1, name='AcqOptimizer', opt_str='rs', viz_acq=True)\n",
      "best_cost 0\n",
      "best_cost 0.04472832271810501\n",
      "best_cost 0.09574603773266976\n",
      "best_cost 0.10945535304845877\n",
      "best_cost 0.14771738652166277\n",
      "best_cost 0.1542679906442097\n",
      "best_cost 0.18728640306672473\n",
      "best_cost 0.19706692142641002\n",
      "best_cost 0.19744396924736574\n",
      "best_cost 0.2058545504805307\n",
      "best_cost 0.23290835279650013\n",
      "best_cost 0.23654958589248198\n",
      "best_cost 0.23920854994319418\n",
      "best_cost 0.2516493114296898\n",
      "best_cost 0.2627425523654201\n",
      "best_cost 0.2804927072607508\n",
      "best_cost 0.28177298140029605\n",
      "best_cost 0.2892865998970269\n",
      "best_cost 0.29354708188165013\n",
      "best_cost 0.302034499030132\n",
      "best_cost 0.30548328535926994\n",
      "best_cost 0.3076614029161422\n",
      "best_cost 0.31543874598752275\n",
      "best_cost 0.32237466659647795\n",
      "best_cost 0.33076346098016307\n",
      "best_cost 0.33336917065003124\n",
      "best_cost 0.3342650516760024\n",
      "best_cost 0.3422328855469199\n",
      "best_cost 0.3464792139510475\n",
      "best_cost 0.3510378637510756\n",
      "best_cost 0.35589388304746716\n",
      "best_cost 0.35744463226734835\n",
      "best_cost 0.36688818050141236\n",
      "best_cost 0.3676207230004038\n",
      "best_cost 0.36850966637540417\n",
      "best_cost 0.37210862782649956\n",
      "best_cost 0.3741393415013148\n",
      "best_cost 0.3828715485196774\n",
      "best_cost 0.3862685129032659\n",
      "best_cost 0.3905516626314529\n",
      "best_cost 0.39253603480726107\n",
      "best_cost 0.3927741924178014\n",
      "best_cost 0.39876955498881306\n",
      "best_cost 0.4019607908558076\n",
      "best_cost 0.4020800363624406\n",
      "best_cost 0.4044948920693645\n",
      "best_cost 0.40467420278846\n",
      "best_cost 0.4097568537089509\n",
      "best_cost 0.4114809483635442\n",
      "best_cost 0.4118223474878904\n",
      "best_cost 0.41238507251859224\n",
      "best_cost 0.4158465646689802\n",
      "best_cost 0.41668131250724594\n",
      "best_cost 0.4182953328554553\n",
      "best_cost 0.42255134785390913\n",
      "best_cost 0.422818675114921\n",
      "best_cost 0.42828897470750493\n",
      "best_cost 0.4299986219854226\n",
      "best_cost 0.4311255307508268\n",
      "best_cost 0.43165108369446736\n",
      "best_cost 0.43497731672660445\n",
      "best_cost 0.43855532703834377\n",
      "best_cost 0.4399739157903615\n",
      "best_cost 0.44340906484403897\n",
      "best_cost 0.44409748290531614\n",
      "best_cost 0.4492617081683583\n",
      "best_cost 0.4494894425140823\n",
      "best_cost 0.45230585591365746\n",
      "best_cost 0.4545199510484923\n",
      "best_cost 0.45500383601387395\n",
      "best_cost 0.45938597755281774\n",
      "best_cost 0.460502876120231\n",
      "best_cost 0.46131430923053274\n",
      "best_cost 0.46163021087282163\n",
      "best_cost 0.4634678532849945\n",
      "best_cost 0.46505522487887996\n",
      "best_cost 0.4656543157918327\n",
      "best_cost 0.4687863902871352\n",
      "best_cost 0.46903862136359753\n",
      "best_cost 0.46951409454117954\n",
      "best_cost 0.4720057319697999\n",
      "best_cost 0.47378165432573893\n",
      "best_cost 0.4757939155910387\n",
      "best_cost 0.4761497843652227\n",
      "best_cost 0.47649888660116235\n",
      "best_cost 0.48222670058337913\n",
      "best_cost 0.48330985266781545\n",
      "best_cost 0.48486162828850166\n",
      "best_cost 0.4849662685083236\n",
      "best_cost 0.4859317031385184\n",
      "best_cost 0.4889979671334401\n",
      "best_cost 0.493451615498423\n",
      "best_cost 0.494707381570473\n",
      "best_cost 0.4950986189715154\n",
      "best_cost 0.4952861456270463\n",
      "best_cost 0.49869854902427413\n",
      "best_cost 0.49887805501564486\n",
      "best_cost 0.49942725664668397\n",
      "best_cost 0.4994592704958607\n",
      "best_cost 0.49984621681999\n",
      "best_cost 0.5011062889893565\n",
      "best_cost 0.5019647221708905\n",
      "best_cost 0.5020141245954977\n",
      "best_cost 0.5024547193103082\n",
      "best_cost 0.5033120556629298\n",
      "best_cost 0.5055306113905746\n",
      "best_cost 0.5056670087240223\n",
      "best_cost 0.5061883856715281\n",
      "best_cost 0.5062800642028411\n",
      "best_cost 0.507005991110703\n",
      "best_cost 0.5073175363464117\n",
      "best_cost 0.5089278750248194\n",
      "best_cost 0.5089599052135672\n",
      "best_cost 0.5104690008464101\n",
      "best_cost 0.5130951036030069\n",
      "best_cost 0.5141116683853397\n",
      "best_cost 0.5141466187018631\n",
      "best_cost 0.5176108603555691\n",
      "best_cost 0.5178321731310305\n",
      "best_cost 0.5196586667467629\n",
      "best_cost 0.5199588730429294\n",
      "best_cost 0.5201832065813743\n",
      "best_cost 0.5212786866847978\n",
      "best_cost 0.5216388228947961\n",
      "best_cost 0.5242422076077078\n",
      "best_cost 0.5252459757086001\n",
      "best_cost 0.5257153340147696\n",
      "best_cost 0.5265889347961423\n",
      "best_cost 0.527847379206148\n",
      "best_cost 0.5289012232711079\n",
      "best_cost 0.5312131109647655\n",
      "best_cost 0.5315252132183295\n",
      "best_cost 0.5320646989918756\n",
      "best_cost 0.5330660336694306\n",
      "best_cost 0.5338302553947754\n",
      "best_cost 0.5364420249632229\n",
      "best_cost 0.5367582175018792\n",
      "best_cost 0.5396173418180295\n",
      "best_cost 0.5397373368146272\n",
      "best_cost 0.54076471956205\n",
      "best_cost 0.5413514249907236\n",
      "best_cost 0.5424685902291733\n",
      "best_cost 0.5435431199385476\n",
      "best_cost 0.5438894102818779\n",
      "best_cost 0.5446162745721428\n",
      "best_cost 0.544911729603325\n",
      "best_cost 0.5457833589404901\n",
      "best_cost 0.546526040753945\n",
      "best_cost 0.5476722625827655\n",
      "best_cost 0.5483414934066011\n",
      "best_cost 0.5488897137373443\n",
      "best_cost 0.5489534769250972\n",
      "best_cost 0.5512593718316561\n",
      "best_cost 0.551507665372573\n",
      "best_cost 0.551837255324517\n",
      "best_cost 0.5519284998743326\n",
      "best_cost 0.5539042300698096\n",
      "best_cost 0.5539541745988503\n",
      "best_cost 0.5540598629639077\n",
      "best_cost 0.5560622175375951\n",
      "best_cost 0.5565360988926347\n",
      "best_cost 0.5570536635895202\n",
      "best_cost 0.5578776859523362\n",
      "best_cost 0.5580782780206721\n",
      "best_cost 0.5581444411908101\n",
      "best_cost 0.5584483336015085\n",
      "best_cost 0.5591475985235566\n",
      "best_cost 0.5595246774304681\n",
      "best_cost 0.5602895269783834\n",
      "best_cost 0.5603686036307516\n",
      "best_cost 0.5612661528184344\n",
      "best_cost 0.5623970986690254\n",
      "best_cost 0.5624932000669014\n",
      "best_cost 0.5639566161993341\n",
      "best_cost 0.5650371580009037\n",
      "best_cost 0.5651270006786491\n",
      "best_cost 0.5651849678897045\n",
      "best_cost 0.565248361160982\n",
      "best_cost 0.5652734183134065\n",
      "best_cost 0.5658515193288747\n",
      "best_cost 0.566579421553882\n",
      "best_cost 0.5677933935747792\n",
      "best_cost 0.5706712930928339\n",
      "best_cost 0.571011115884495\n",
      "best_cost 0.5712219580375144\n",
      "best_cost 0.5722908298131033\n",
      "best_cost 0.5726769922483403\n",
      "best_cost 0.5741166126620112\n",
      "best_cost 0.5753091728065893\n",
      "best_cost 0.5754959010593186\n",
      "best_cost 0.5760007982286841\n",
      "best_cost 0.5769170647174666\n",
      "best_cost 0.5779347765678025\n",
      "best_cost 0.5783855350536931\n",
      "best_cost 0.5784140289054751\n",
      "best_cost 0.5786929975778496\n",
      "best_cost 0.5791630689934393\n",
      "best_cost 0.5806027686857578\n",
      "best_cost 0.5831873167265866\n",
      "best_cost 0.5832079733239572\n",
      "best_cost 0.5843976177717938\n",
      "best_cost 0.5856704629995126\n",
      "best_cost 0.5865472303622614\n",
      "best_cost 0.5870272828265621\n",
      "best_cost 0.5871608168083906\n",
      "best_cost 0.5879456861467891\n",
      "best_cost 0.5881935483299572\n",
      "best_cost 0.5891380036297951\n",
      "best_cost 0.5904850745003081\n",
      "best_cost 0.5907725721534187\n",
      "best_cost 0.5914254208269845\n",
      "best_cost 0.5915249841260957\n",
      "best_cost 0.5930165127441385\n",
      "best_cost 0.5934473960580091\n",
      "best_cost 0.5936499671200746\n",
      "best_cost 0.5937172489542448\n",
      "best_cost 0.5937835907422693\n",
      "best_cost 0.5940390651404002\n",
      "best_cost 0.5943711622695598\n",
      "best_cost 0.5943794690537756\n",
      "best_cost 0.5957493097289146\n",
      "best_cost 0.5957749289932626\n",
      "best_cost 0.5959156206143108\n",
      "best_cost 0.5964458260077159\n",
      "best_cost 0.5967721848624064\n",
      "best_cost 0.5970945065005906\n",
      "best_cost 0.5974033241868708\n",
      "best_cost 0.5974142372787816\n",
      "best_cost 0.5978787895939475\n",
      "best_cost 0.5983994205204402\n",
      "best_cost 0.5984377261987464\n",
      "best_cost 0.5993218837748631\n",
      "best_cost 0.6006242579590786\n",
      "best_cost 0.6020758748012089\n",
      "best_cost 0.60222769293435\n",
      "best_cost 0.6026043638305778\n",
      "best_cost 0.603367948433073\n",
      "best_cost 0.6041558302534062\n",
      "best_cost 0.604389444517075\n",
      "best_cost 0.6047868050824325\n",
      "best_cost 0.6050587368259821\n",
      "best_cost 0.6050850418756719\n",
      "best_cost 0.6061574827404932\n",
      "best_cost 0.606446133693479\n",
      "best_cost 0.6064986992404628\n",
      "best_cost 0.6065508863535014\n",
      "best_cost 0.6075012589242132\n",
      "best_cost 0.6078262163562307\n",
      "best_cost 0.6080734199388007\n",
      "best_cost 0.6082055471118184\n",
      "best_cost 0.6093525269311435\n",
      "best_cost 0.6096188345730555\n",
      "best_cost 0.609712400005586\n",
      "best_cost 0.6099225058407578\n",
      "best_cost 0.6101752633469493\n",
      "best_cost 0.610343406877043\n",
      "best_cost 0.6105541152414777\n",
      "best_cost 0.6106939885771479\n",
      "best_cost 0.6108166070335572\n",
      "best_cost 0.6108750434489956\n",
      "best_cost 0.6113137377804547\n",
      "best_cost 0.6115523392744451\n",
      "best_cost 0.6115939354186031\n",
      "best_cost 0.6120726256827966\n",
      "best_cost 0.6121828530699476\n",
      "best_cost 0.6122319735192447\n",
      "best_cost 0.6132135528522114\n",
      "best_cost 0.6147310955382661\n",
      "best_cost 0.615221635773177\n",
      "best_cost 0.615523061427788\n",
      "best_cost 0.6161230712721084\n",
      "best_cost 0.6165850641514261\n",
      "best_cost 0.6168585278552503\n",
      "best_cost 0.6169707961803537\n",
      "best_cost 0.617284494627304\n",
      "best_cost 0.6178001872168419\n",
      "best_cost 0.6187620877009283\n",
      "best_cost 0.6192685155367674\n",
      "best_cost 0.6198924974120443\n",
      "best_cost 0.6208264996790287\n",
      "best_cost 0.6215167498268073\n",
      "best_cost 0.6216802758128601\n",
      "best_cost 0.6223607321226738\n",
      "best_cost 0.6231279401213747\n",
      "best_cost 0.6236091806967354\n",
      "best_cost 0.6236649418059277\n",
      "best_cost 0.6237268814148158\n",
      "best_cost 0.6237336556037303\n",
      "best_cost 0.623928381845346\n",
      "best_cost 0.6242317596095814\n",
      "best_cost 0.6255043666884381\n",
      "best_cost 0.6274689223715766\n",
      "best_cost 0.6276999129743093\n",
      "best_cost 0.6288338304441721\n",
      "best_cost 0.6292366742685349\n",
      "best_cost 0.6294607546600726\n",
      "best_cost 0.6302879511915893\n",
      "best_cost 0.6304287871266228\n",
      "best_cost 0.6308343545762893\n",
      "best_cost 0.6309298609475185\n",
      "best_cost 0.6312885976030018\n",
      "best_cost 0.6316442805827358\n",
      "best_cost 0.631871160643876\n",
      "best_cost 0.632527120013719\n",
      "best_cost 0.6326035905366592\n",
      "best_cost 0.6328636539317838\n",
      "best_cost 0.6329668841993823\n",
      "best_cost 0.6337407219701519\n",
      "best_cost 0.634241757651151\n",
      "best_cost 0.634833190019324\n",
      "best_cost 0.6351630898130336\n",
      "best_cost 0.6359978731136742\n",
      "best_cost 0.6362027036092872\n",
      "best_cost 0.6366261454666604\n",
      "best_cost 0.6369286010685433\n",
      "best_cost 0.6371072035128136\n",
      "best_cost 0.6374524407670579\n",
      "best_cost 0.637566892394773\n",
      "best_cost 0.6377437365398113\n",
      "best_cost 0.6380515816829637\n",
      "best_cost 0.6380538414917798\n",
      "best_cost 0.6385834130872505\n",
      "best_cost 0.6391496947509931\n",
      "best_cost 0.6393228232020827\n",
      "best_cost 0.6394656420843279\n",
      "best_cost 0.640742729759505\n",
      "best_cost 0.6410247988478588\n",
      "best_cost 0.6418345647222206\n",
      "best_cost 0.6428286308640774\n",
      "best_cost 0.6431538220221973\n",
      "best_cost 0.6436891415487953\n",
      "best_cost 0.64454242954964\n",
      "best_cost 0.6445656960054913\n",
      "best_cost 0.644752506285778\n",
      "best_cost 0.6451421047136126\n",
      "best_cost 0.6453753804152667\n",
      "best_cost 0.6454075018685923\n",
      "best_cost 0.6458921970747853\n",
      "best_cost 0.645980050511981\n",
      "best_cost 0.6459879206562649\n",
      "best_cost 0.6466830295234662\n",
      "best_cost 0.6470009457665598\n",
      "best_cost 0.647219453252498\n",
      "best_cost 0.647486865378263\n",
      "best_cost 0.6476199536238338\n",
      "best_cost 0.6479288267651142\n",
      "best_cost 0.6479528900888509\n",
      "best_cost 0.6487298587070387\n",
      "best_cost 0.6491373599594048\n",
      "best_cost 0.6496924089718867\n",
      "best_cost 0.6500862554054998\n",
      "best_cost 0.6505708714090657\n",
      "best_cost 0.6516670414510848\n",
      "best_cost 0.6517438400500575\n",
      "best_cost 0.6517776280469236\n",
      "best_cost 0.6520017128093503\n",
      "best_cost 0.653078972040056\n",
      "best_cost 0.6531618873311789\n",
      "best_cost 0.6533270926552177\n",
      "best_cost 0.6541725421380131\n",
      "best_cost 0.6543094343980864\n",
      "best_cost 0.6544331406383894\n",
      "best_cost 0.6544462373783444\n",
      "best_cost 0.6548948845249605\n",
      "best_cost 0.6549859702023502\n",
      "best_cost 0.6551980950650276\n",
      "best_cost 0.6552013544797901\n",
      "best_cost 0.6557325428758844\n",
      "best_cost 0.6559067742824767\n",
      "best_cost 0.6560215280628969\n",
      "best_cost 0.6566886178820601\n",
      "best_cost 0.6569554900075423\n",
      "best_cost 0.6575176291896518\n",
      "best_cost 0.6576560887047724\n",
      "best_cost 0.6578392118731595\n",
      "best_cost 0.6585195304572762\n",
      "best_cost 0.6588673150831847\n",
      "best_cost 0.6589108100912913\n",
      "best_cost 0.6591074376503165\n",
      "best_cost 0.6593384702219183\n",
      "best_cost 0.6593846630850786\n",
      "best_cost 0.6599497920614885\n",
      "best_cost 0.6602069968251303\n",
      "best_cost 0.660326335356177\n",
      "best_cost 0.6607888135895976\n",
      "best_cost 0.6610759250798905\n",
      "best_cost 0.6616304030287974\n",
      "best_cost 0.6620526175395733\n",
      "best_cost 0.6621731776946607\n",
      "best_cost 0.6622581589483847\n",
      "best_cost 0.6625336184294266\n",
      "best_cost 0.6631104911069448\n",
      "best_cost 0.6633609287186193\n",
      "best_cost 0.6634860790271551\n",
      "best_cost 0.6637284473924805\n",
      "best_cost 0.6645055072749184\n",
      "best_cost 0.6645678933682524\n",
      "best_cost 0.6646794887088485\n",
      "best_cost 0.6647477777302924\n",
      "best_cost 0.6661343801794812\n",
      "best_cost 0.6662324324205708\n",
      "best_cost 0.666816142197024\n",
      "best_cost 0.6669058026501085\n",
      "best_cost 0.6677185745346341\n",
      "best_cost 0.6679629154461553\n",
      "best_cost 0.6681011389321669\n",
      "best_cost 0.668591466428627\n",
      "best_cost 0.6687551411652952\n",
      "best_cost 0.66881020966131\n",
      "best_cost 0.6690762950788152\n",
      "best_cost 0.6692195734505006\n",
      "best_cost 0.6692253025083628\n",
      "best_cost 0.6693749952829453\n",
      "best_cost 0.6694591061944961\n",
      "best_cost 0.6696004814151075\n",
      "best_cost 0.6696207138585537\n",
      "best_cost 0.6697259124796802\n",
      "best_cost 0.6697386260509619\n",
      "best_cost 0.6703111552756289\n",
      "best_cost 0.6707193750921794\n",
      "best_cost 0.6710791127122562\n",
      "best_cost 0.671281894368642\n",
      "best_cost 0.6725943093421463\n",
      "best_cost 0.672766491340361\n",
      "best_cost 0.6728856566838892\n",
      "best_cost 0.6730259485622039\n",
      "best_cost 0.6733758584288554\n",
      "best_cost 0.6739278556513322\n",
      "best_cost 0.674417705600584\n",
      "best_cost 0.6748442568986965\n",
      "best_cost 0.6748612443892614\n",
      "best_cost 0.675056110398067\n",
      "best_cost 0.675096360370476\n",
      "best_cost 0.6752455144973943\n",
      "best_cost 0.6758563010955125\n",
      "best_cost 0.6759450072945636\n",
      "best_cost 0.6762681885714263\n",
      "best_cost 0.676382841097406\n",
      "best_cost 0.6768750048148204\n",
      "best_cost 0.676976325348758\n",
      "best_cost 0.6774020745637135\n",
      "best_cost 0.6775358549268475\n",
      "best_cost 0.6776067969681534\n",
      "best_cost 0.6781076623744431\n",
      "best_cost 0.678190838152319\n",
      "best_cost 0.6783978774063737\n",
      "best_cost 0.6785147941046457\n",
      "best_cost 0.6796876271607697\n",
      "best_cost 0.6800757433737843\n",
      "best_cost 0.6802181623405801\n",
      "best_cost 0.680794427127982\n",
      "best_cost 0.681142887156678\n",
      "best_cost 0.6812090824814536\n",
      "best_cost 0.681235964549838\n",
      "best_cost 0.6812993717042557\n",
      "best_cost 0.6813153080128991\n",
      "best_cost 0.6815693006381431\n",
      "best_cost 0.6816951132524531\n",
      "best_cost 0.6817507390458919\n",
      "best_cost 0.6818562140977573\n",
      "best_cost 0.6821987982455464\n",
      "best_cost 0.6824451459865017\n",
      "best_cost 0.6826580817738273\n",
      "best_cost 0.6826901511452352\n",
      "best_cost 0.6828272730689202\n",
      "best_cost 0.682846441552063\n",
      "best_cost 0.6835445313141428\n",
      "best_cost 0.6838610793409128\n",
      "best_cost 0.6841069405877203\n",
      "best_cost 0.6846870933146847\n",
      "best_cost 0.6846956746919888\n",
      "best_cost 0.6852364219446341\n",
      "best_cost 0.685393097036004\n",
      "best_cost 0.6856550504120515\n",
      "best_cost 0.6857170955437655\n",
      "best_cost 0.6860459580974556\n",
      "best_cost 0.6861842243526137\n",
      "best_cost 0.6863804384248378\n",
      "best_cost 0.6870175256161775\n",
      "best_cost 0.6873646829789313\n",
      "best_cost 0.687704171925722\n",
      "best_cost 0.6877857583018532\n",
      "best_cost 0.6879990657755024\n",
      "best_cost 0.6882494556403356\n",
      "best_cost 0.6883667279619494\n",
      "best_cost 0.6887389197552105\n",
      "best_cost 0.6889143697678568\n",
      "best_cost 0.6897424180479039\n",
      "best_cost 0.6899928716810413\n",
      "best_cost 0.6901286649327112\n",
      "best_cost 0.6902033694581848\n",
      "best_cost 0.6904037796003459\n",
      "best_cost 0.6904778774100693\n",
      "best_cost 0.6906553433168174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alex/miniconda3/envs/dev/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alex/miniconda3/envs/dev/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alex/miniconda3/envs/dev/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/alex/miniconda3/envs/dev/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/alex/miniconda3/envs/dev/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/alex/miniconda3/envs/dev/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/alex/miniconda3/envs/dev/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*[TIME] [Sample 1 execution paths] Elapsed: 228.39 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ed6c2d1583ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     acqopt = AcqOptimizer({'x_test': x_test,\n\u001b[1;32m      7\u001b[0m                            'n_path': 1})\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mx_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macqopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Acq optimizer x_next = {x_next}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Finished iter i = {i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage1/Documents/repos/bayesian-algorithm-execution/bax/acq/acqoptimize.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, model, algo)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Sample execution paths and outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mexe_path_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_exe_path_and_output_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_output_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage1/Documents/repos/bayesian-algorithm-execution/bax/acq/acqoptimize.py\u001b[0m in \u001b[0;36mget_exe_path_and_output_samples\u001b[0;34m(self, fs, algo)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Sample {self.params.n_path} execution paths\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mexe_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_exe_path_and_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0mexe_path_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexe_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0moutput_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage1/Documents/repos/bayesian-algorithm-execution/bax/acq/acqoptimize.py\u001b[0m in \u001b[0;36msample_exe_path_and_output\u001b[0;34m(self, fs, algo)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;34m\"\"\"Return execution path sample given a function sample and algorithm.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_query_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mexe_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_algorithm_on_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexe_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage1/Documents/repos/bayesian-algorithm-execution/bax/alg/algorithms.py\u001b[0m in \u001b[0;36mrun_algorithm_on_f\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mmin_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdijkstras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexe_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage1/Documents/repos/bayesian-algorithm-execution/bax/alg/algorithms.py\u001b[0m in \u001b[0;36mdijkstras\u001b[0;34m(start, goal)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mneighbor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                     \u001b[0mstep_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m                     \u001b[0;31m# comment out version that stores extra info in each Vertex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                     \u001b[0;31m# if not hasattr(neighbor, \"explored\"):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage1/Documents/repos/bayesian-algorithm-execution/bax/alg/algorithms.py\u001b[0m in \u001b[0;36mdistance\u001b[0;34m(u, v)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVertex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVertex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mu_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mfu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mexe_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage1/Documents/repos/bayesian-algorithm-execution/bax/models/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;34m\"\"\"Class is callable and returns self.get_y(x).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage1/Documents/repos/bayesian-algorithm-execution/bax/models/function.py\u001b[0m in \u001b[0;36mget_y\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# Sample y from model posterior predictive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_post_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage1/Documents/repos/bayesian-algorithm-execution/bax/models/simple_gp.py\u001b[0m in \u001b[0;36msample_post_pred\u001b[0;34m(self, x, n_samp)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_post_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;34m\"\"\"Get samples from gp posterior predictive for a single input x.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0msample_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_post_pred_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msample_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage1/Documents/repos/bayesian-algorithm-execution/bax/models/simple_gp.py\u001b[0m in \u001b[0;36msample_post_pred_list\u001b[0;34m(self, x_list, n_samp, full_cov)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# For now, return posterior (assuming low-noise case)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# TODO: update this function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_post_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_post_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage1/Documents/repos/bayesian-algorithm-execution/bax/models/simple_gp.py\u001b[0m in \u001b[0;36msample_post_list\u001b[0;34m(self, x_list, n_samp, full_cov)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m# If data is not empty:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_post_mu_cov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_normal_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage1/Documents/repos/bayesian-algorithm-execution/bax/models/simple_gp.py\u001b[0m in \u001b[0;36mget_post_mu_cov\u001b[0;34m(self, x_list, full_cov)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# If data is not empty:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         mu, cov = gp_post(\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage1/Documents/repos/bayesian-algorithm-execution/bax/models/gp/gp_utils.py\u001b[0m in \u001b[0;36mgp_post\u001b[0;34m(x_train, y_train, x_pred, ls, alpha, sigma, kernel, full_cov)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;34m\"\"\"Compute parameters of GP posterior\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mk11_nonoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mlmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cholesky_decomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk11_nonoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'try_first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0msmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_upper_triangular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolve_lower_triangular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mk21\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage1/Documents/repos/bayesian-algorithm-execution/bax/models/gp/gp_utils.py\u001b[0m in \u001b[0;36mget_cholesky_decomp\u001b[0;34m(k11_nonoise, sigma, psd_str)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mk11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk11_nonoise\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk11_nonoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mstable_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinAlgError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_cholesky_decomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk11_nonoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'project_first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage1/Documents/repos/bayesian-algorithm-execution/bax/models/gp/gp_utils.py\u001b[0m in \u001b[0;36mstable_cholesky\u001b[0;34m(mmat, make_psd, verbose)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmmat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mlmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinAlgError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmake_psd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# BAX iterations\n",
    "n_iter = 40\n",
    "\n",
    "for i in range(n_iter):\n",
    "    # Optimize acquisition function\n",
    "    acqopt = AcqOptimizer({'x_test': x_test,\n",
    "                           'n_path': 1})\n",
    "    x_next = acqopt.optimize(model, algo)\n",
    "    print(f'Acq optimizer x_next = {x_next}')\n",
    "    print(f'Finished iter i = {i}')\n",
    "\n",
    "    # Query function, update data\n",
    "    y_next = f(x_next)\n",
    "    data.x.append(x_next)\n",
    "    data.y.append(y_next)\n",
    "\n",
    "    # Update model\n",
    "    model = SimpleGp(gp_params)\n",
    "    model.set_data(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
